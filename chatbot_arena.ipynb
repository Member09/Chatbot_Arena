{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c189e8d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-11T21:24:56.519116Z",
     "iopub.status.busy": "2024-06-11T21:24:56.518624Z",
     "iopub.status.idle": "2024-06-11T21:24:57.393007Z",
     "shell.execute_reply": "2024-06-11T21:24:57.391996Z"
    },
    "papermill": {
     "duration": 0.882192,
     "end_time": "2024-06-11T21:24:57.395630",
     "exception": false,
     "start_time": "2024-06-11T21:24:56.513438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/lmsys-chatbot-arena/sample_submission.csv\n",
      "/kaggle/input/lmsys-chatbot-arena/train.csv\n",
      "/kaggle/input/lmsys-chatbot-arena/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9457572",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T21:24:57.406676Z",
     "iopub.status.busy": "2024-06-11T21:24:57.405341Z",
     "iopub.status.idle": "2024-06-11T21:25:04.354980Z",
     "shell.execute_reply": "2024-06-11T21:25:04.353763Z"
    },
    "papermill": {
     "duration": 6.95716,
     "end_time": "2024-06-11T21:25:04.357924",
     "exception": false,
     "start_time": "2024-06-11T21:24:57.400764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57477, 9) (3, 4)\n"
     ]
    }
   ],
   "source": [
    "train_file = \"/kaggle/input/lmsys-chatbot-arena/train.csv\"\n",
    "test_file = \"/kaggle/input/lmsys-chatbot-arena/test.csv\"\n",
    "sample_file = \"/kaggle/input/lmsys-chatbot-arena/sample_submission.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_file)\n",
    "test_df = pd.read_csv(test_file)\n",
    "\n",
    "sample_df = pd.read_csv(sample_file)\n",
    "\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6367ba51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T21:25:04.365204Z",
     "iopub.status.busy": "2024-06-11T21:25:04.364824Z",
     "iopub.status.idle": "2024-06-11T21:25:04.394165Z",
     "shell.execute_reply": "2024-06-11T21:25:04.392939Z"
    },
    "papermill": {
     "duration": 0.035477,
     "end_time": "2024-06-11T21:25:04.396346",
     "exception": false,
     "start_time": "2024-06-11T21:25:04.360869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"A marriage license is a legal document that ...</td>\n",
       "      <td>[\"A marriage license and a marriage certificat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[\"How can I create a test set for a very rare ...</td>\n",
       "      <td>[\"Creating a test set for a very rare category...</td>\n",
       "      <td>[\"When building a classifier for a very rare c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
       "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
       "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57472</th>\n",
       "      <td>4294656694</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>[\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...</td>\n",
       "      <td>[\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...</td>\n",
       "      <td>[\"Here is how that mnemonic represents the dig...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57473</th>\n",
       "      <td>4294692063</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>[\"In python, implement a naive Bayes with gaus...</td>\n",
       "      <td>[\"Here is an implementation of a naive Bayes c...</td>\n",
       "      <td>[\"Sure! Here's an implementation of a naive Ba...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57474</th>\n",
       "      <td>4294710549</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>[\"is it unethical to work on building weapons?...</td>\n",
       "      <td>[\"Working on weapons technology raises some et...</td>\n",
       "      <td>[\"It depends on the context. Weapons can be us...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57475</th>\n",
       "      <td>4294899228</td>\n",
       "      <td>palm-2</td>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>[\"If a bait contains 0,0025% bromadiolon then ...</td>\n",
       "      <td>[\"Bromadiolone is a rodenticide which is most ...</td>\n",
       "      <td>[\"As an AI language model, I do not promote or...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57476</th>\n",
       "      <td>4294947231</td>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>[\"three kids eat three apples in three days, h...</td>\n",
       "      <td>[\"27 apples\"]</td>\n",
       "      <td>[\"If three kids eat three apples in three days...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57477 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             model_a              model_b  \\\n",
       "0           30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1           53567           koala-13b           gpt-4-0613   \n",
       "2           65089  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3           96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4          198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "...           ...                 ...                  ...   \n",
       "57472  4294656694          gpt-4-0613             claude-1   \n",
       "57473  4294692063          claude-2.0     llama-2-13b-chat   \n",
       "57474  4294710549            claude-1           alpaca-13b   \n",
       "57475  4294899228              palm-2       tulu-2-dpo-70b   \n",
       "57476  4294947231  gemini-pro-dev-api   gpt-4-1106-preview   \n",
       "\n",
       "                                                  prompt  \\\n",
       "0      [\"Is it morally right to try to have a certain...   \n",
       "1      [\"What is the difference between marriage lice...   \n",
       "2      [\"explain function calling. how would you call...   \n",
       "3      [\"How can I create a test set for a very rare ...   \n",
       "4      [\"What is the best way to travel from Tel-Aviv...   \n",
       "...                                                  ...   \n",
       "57472  [\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...   \n",
       "57473  [\"In python, implement a naive Bayes with gaus...   \n",
       "57474  [\"is it unethical to work on building weapons?...   \n",
       "57475  [\"If a bait contains 0,0025% bromadiolon then ...   \n",
       "57476  [\"three kids eat three apples in three days, h...   \n",
       "\n",
       "                                              response_a  \\\n",
       "0      [\"The question of whether it is morally right ...   \n",
       "1      [\"A marriage license is a legal document that ...   \n",
       "2      [\"Function calling is the process of invoking ...   \n",
       "3      [\"Creating a test set for a very rare category...   \n",
       "4      [\"The best way to travel from Tel Aviv to Jeru...   \n",
       "...                                                  ...   \n",
       "57472  [\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...   \n",
       "57473  [\"Here is an implementation of a naive Bayes c...   \n",
       "57474  [\"Working on weapons technology raises some et...   \n",
       "57475  [\"Bromadiolone is a rodenticide which is most ...   \n",
       "57476                                      [\"27 apples\"]   \n",
       "\n",
       "                                              response_b  winner_model_a  \\\n",
       "0      [\"As an AI, I don't have personal beliefs or o...               1   \n",
       "1      [\"A marriage license and a marriage certificat...               0   \n",
       "2      [\"Function calling is the process of invoking ...               0   \n",
       "3      [\"When building a classifier for a very rare c...               1   \n",
       "4      [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
       "...                                                  ...             ...   \n",
       "57472  [\"Here is how that mnemonic represents the dig...               1   \n",
       "57473  [\"Sure! Here's an implementation of a naive Ba...               1   \n",
       "57474  [\"It depends on the context. Weapons can be us...               1   \n",
       "57475  [\"As an AI language model, I do not promote or...               0   \n",
       "57476  [\"If three kids eat three apples in three days...               1   \n",
       "\n",
       "       winner_model_b  winner_tie  \n",
       "0                   0           0  \n",
       "1                   1           0  \n",
       "2                   0           1  \n",
       "3                   0           0  \n",
       "4                   1           0  \n",
       "...               ...         ...  \n",
       "57472               0           0  \n",
       "57473               0           0  \n",
       "57474               0           0  \n",
       "57475               1           0  \n",
       "57476               0           0  \n",
       "\n",
       "[57477 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7e90b75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T21:25:04.404235Z",
     "iopub.status.busy": "2024-06-11T21:25:04.403871Z",
     "iopub.status.idle": "2024-06-11T21:25:04.417350Z",
     "shell.execute_reply": "2024-06-11T21:25:04.416133Z"
    },
    "papermill": {
     "duration": 0.020105,
     "end_time": "2024-06-11T21:25:04.419665",
     "exception": false,
     "start_time": "2024-06-11T21:25:04.399560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        id                                             prompt  \\\n",
       " 0   136060  [\"I have three oranges today, I ate an orange ...   \n",
       " 1   211333  [\"You are a mediator in a heated political deb...   \n",
       " 2  1233961  [\"How to initialize the classification head wh...   \n",
       " \n",
       "                                           response_a  \\\n",
       " 0                    [\"You have two oranges today.\"]   \n",
       " 1  [\"Thank you for sharing the details of the sit...   \n",
       " 2  [\"When you want to initialize the classificati...   \n",
       " \n",
       "                                           response_b  \n",
       " 0  [\"You still have three oranges. Eating an oran...  \n",
       " 1  [\"Mr Reddy and Ms Blue both have valid points ...  \n",
       " 2  [\"To initialize the classification head when p...  ,\n",
       "         id  winner_model_a  winner_model_b  winner_tie\n",
       " 0   136060        0.333333        0.333333    0.333333\n",
       " 1   211333        0.333333        0.333333    0.333333\n",
       " 2  1233961        0.333333        0.333333    0.333333)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df, sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fb7a5bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T21:25:04.428284Z",
     "iopub.status.busy": "2024-06-11T21:25:04.427354Z",
     "iopub.status.idle": "2024-06-11T21:25:04.473615Z",
     "shell.execute_reply": "2024-06-11T21:25:04.472566Z"
    },
    "papermill": {
     "duration": 0.053234,
     "end_time": "2024-06-11T21:25:04.476157",
     "exception": false,
     "start_time": "2024-06-11T21:25:04.422923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries in Trainset : 57477\n",
      "Unique models used as 'model_a': 64 | Unique models used as 'model_b': 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>count_a</th>\n",
       "      <th>count_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>3678</td>\n",
       "      <td>3709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>3553</td>\n",
       "      <td>3530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>3099</td>\n",
       "      <td>3066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>2859</td>\n",
       "      <td>2724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>2087</td>\n",
       "      <td>2035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>falcon-180b-chat</td>\n",
       "      <td>145</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>openchat-3.5-0106</td>\n",
       "      <td>108</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>qwen1.5-7b-chat</td>\n",
       "      <td>106</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>qwen1.5-4b-chat</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>mistral-7b-instruct-v0.2</td>\n",
       "      <td>54</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  count_a  count_b\n",
       "0         gpt-4-1106-preview     3678     3709\n",
       "1         gpt-3.5-turbo-0613     3553     3530\n",
       "2                 gpt-4-0613     3099     3066\n",
       "3                 claude-2.1     2859     2724\n",
       "4                 gpt-4-0314     2087     2035\n",
       "..                       ...      ...      ...\n",
       "59          falcon-180b-chat      145      141\n",
       "60         openchat-3.5-0106      108      136\n",
       "61           qwen1.5-7b-chat      106      102\n",
       "62           qwen1.5-4b-chat      100      100\n",
       "63  mistral-7b-instruct-v0.2       54       46\n",
       "\n",
       "[64 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Total entries in Trainset : {train_df.shape[0]}\")\n",
    "print(f\"Unique models used as 'model_a': {train_df['model_a'].nunique()} | Unique models used as 'model_b': {train_df['model_b'].nunique()}\")\n",
    "models_used = pd.DataFrame(train_df['model_a'].value_counts().reset_index().rename(columns={'model_a':'model', 'count': 'count_a'})).merge(pd.DataFrame(train_df['model_b'].value_counts().reset_index().rename(columns={'model_b':'model', 'count':'count_b'})), on=['model'])\n",
    "models_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d9b92b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T21:25:04.484709Z",
     "iopub.status.busy": "2024-06-11T21:25:04.484342Z",
     "iopub.status.idle": "2024-06-11T21:25:04.499955Z",
     "shell.execute_reply": "2024-06-11T21:25:04.498993Z"
    },
    "papermill": {
     "duration": 0.022435,
     "end_time": "2024-06-11T21:25:04.502197",
     "exception": false,
     "start_time": "2024-06-11T21:25:04.479762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique base model : 39 : \n",
      "\t ['gpt', 'claude', 'vicuna', 'mixtral', 'mistral', 'llama', 'zephyr', 'palm', 'openchat', 'wizardlm', 'koala', 'oasst', 'codellama', 'gemini', 'pplx', 'alpaca', 'yi', 'chatglm', 'RWKV', 'tulu', 'starling', 'qwen', 'chatglm3', 'stripedhyena', 'fastchat', 'openhermes', 'mpt', 'solar', 'deepseek', 'dolly', 'stablelm', 'guanaco', 'llama2', 'chatglm2', 'qwen1.5', 'gpt4all', 'dolphin', 'nous', 'falcon']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>count_a</th>\n",
       "      <th>count_b</th>\n",
       "      <th>base_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>3678</td>\n",
       "      <td>3709</td>\n",
       "      <td>gpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>3553</td>\n",
       "      <td>3530</td>\n",
       "      <td>gpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>3099</td>\n",
       "      <td>3066</td>\n",
       "      <td>gpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>2859</td>\n",
       "      <td>2724</td>\n",
       "      <td>claude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>2087</td>\n",
       "      <td>2035</td>\n",
       "      <td>gpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>falcon-180b-chat</td>\n",
       "      <td>145</td>\n",
       "      <td>141</td>\n",
       "      <td>falcon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>openchat-3.5-0106</td>\n",
       "      <td>108</td>\n",
       "      <td>136</td>\n",
       "      <td>openchat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>qwen1.5-7b-chat</td>\n",
       "      <td>106</td>\n",
       "      <td>102</td>\n",
       "      <td>qwen1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>qwen1.5-4b-chat</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>qwen1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>mistral-7b-instruct-v0.2</td>\n",
       "      <td>54</td>\n",
       "      <td>46</td>\n",
       "      <td>mistral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  count_a  count_b base_model\n",
       "0         gpt-4-1106-preview     3678     3709        gpt\n",
       "1         gpt-3.5-turbo-0613     3553     3530        gpt\n",
       "2                 gpt-4-0613     3099     3066        gpt\n",
       "3                 claude-2.1     2859     2724     claude\n",
       "4                 gpt-4-0314     2087     2035        gpt\n",
       "..                       ...      ...      ...        ...\n",
       "59          falcon-180b-chat      145      141     falcon\n",
       "60         openchat-3.5-0106      108      136   openchat\n",
       "61           qwen1.5-7b-chat      106      102    qwen1.5\n",
       "62           qwen1.5-4b-chat      100      100    qwen1.5\n",
       "63  mistral-7b-instruct-v0.2       54       46    mistral\n",
       "\n",
       "[64 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = lambda x: x[\"model\"].split(\"-\")[0]\n",
    "models_used[\"base_model\"] = models_used.apply(f, axis=1)\n",
    "\n",
    "print(f\"Total unique base model : {models_used['base_model'].nunique()} : \\n\\t {list(models_used['base_model'].unique())}\")\n",
    "models_used"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.253076,
   "end_time": "2024-06-11T21:25:05.028072",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-11T21:24:53.774996",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
