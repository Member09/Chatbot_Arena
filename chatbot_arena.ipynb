{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "271a0c1b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-18T11:17:31.113874Z",
     "iopub.status.busy": "2024-06-18T11:17:31.113464Z",
     "iopub.status.idle": "2024-06-18T11:17:32.067458Z",
     "shell.execute_reply": "2024-06-18T11:17:32.066063Z"
    },
    "papermill": {
     "duration": 0.963986,
     "end_time": "2024-06-18T11:17:32.070790",
     "exception": false,
     "start_time": "2024-06-18T11:17:31.106804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/lmsys-chatbot-arena/sample_submission.csv\n",
      "/kaggle/input/lmsys-chatbot-arena/train.csv\n",
      "/kaggle/input/lmsys-chatbot-arena/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d0551e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T11:17:32.082573Z",
     "iopub.status.busy": "2024-06-18T11:17:32.082020Z",
     "iopub.status.idle": "2024-06-18T11:17:36.079451Z",
     "shell.execute_reply": "2024-06-18T11:17:36.078240Z"
    },
    "papermill": {
     "duration": 4.005698,
     "end_time": "2024-06-18T11:17:36.081808",
     "exception": false,
     "start_time": "2024-06-18T11:17:32.076110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57477, 9) (3, 4)\n"
     ]
    }
   ],
   "source": [
    "train_file = \"/kaggle/input/lmsys-chatbot-arena/train.csv\"\n",
    "test_file = \"/kaggle/input/lmsys-chatbot-arena/test.csv\"\n",
    "sample_file = \"/kaggle/input/lmsys-chatbot-arena/sample_submission.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_file)\n",
    "test_df = pd.read_csv(test_file)\n",
    "\n",
    "sample_df = pd.read_csv(sample_file)\n",
    "\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7995d305",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T11:17:36.092760Z",
     "iopub.status.busy": "2024-06-18T11:17:36.092284Z",
     "iopub.status.idle": "2024-06-18T11:17:36.123411Z",
     "shell.execute_reply": "2024-06-18T11:17:36.122292Z"
    },
    "papermill": {
     "duration": 0.039733,
     "end_time": "2024-06-18T11:17:36.126030",
     "exception": false,
     "start_time": "2024-06-18T11:17:36.086297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"A marriage license is a legal document that ...</td>\n",
       "      <td>[\"A marriage license and a marriage certificat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[\"How can I create a test set for a very rare ...</td>\n",
       "      <td>[\"Creating a test set for a very rare category...</td>\n",
       "      <td>[\"When building a classifier for a very rare c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
       "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
       "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57472</th>\n",
       "      <td>4294656694</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>[\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...</td>\n",
       "      <td>[\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...</td>\n",
       "      <td>[\"Here is how that mnemonic represents the dig...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57473</th>\n",
       "      <td>4294692063</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>[\"In python, implement a naive Bayes with gaus...</td>\n",
       "      <td>[\"Here is an implementation of a naive Bayes c...</td>\n",
       "      <td>[\"Sure! Here's an implementation of a naive Ba...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57474</th>\n",
       "      <td>4294710549</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>[\"is it unethical to work on building weapons?...</td>\n",
       "      <td>[\"Working on weapons technology raises some et...</td>\n",
       "      <td>[\"It depends on the context. Weapons can be us...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57475</th>\n",
       "      <td>4294899228</td>\n",
       "      <td>palm-2</td>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>[\"If a bait contains 0,0025% bromadiolon then ...</td>\n",
       "      <td>[\"Bromadiolone is a rodenticide which is most ...</td>\n",
       "      <td>[\"As an AI language model, I do not promote or...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57476</th>\n",
       "      <td>4294947231</td>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>[\"three kids eat three apples in three days, h...</td>\n",
       "      <td>[\"27 apples\"]</td>\n",
       "      <td>[\"If three kids eat three apples in three days...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57477 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             model_a              model_b  \\\n",
       "0           30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1           53567           koala-13b           gpt-4-0613   \n",
       "2           65089  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3           96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4          198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "...           ...                 ...                  ...   \n",
       "57472  4294656694          gpt-4-0613             claude-1   \n",
       "57473  4294692063          claude-2.0     llama-2-13b-chat   \n",
       "57474  4294710549            claude-1           alpaca-13b   \n",
       "57475  4294899228              palm-2       tulu-2-dpo-70b   \n",
       "57476  4294947231  gemini-pro-dev-api   gpt-4-1106-preview   \n",
       "\n",
       "                                                  prompt  \\\n",
       "0      [\"Is it morally right to try to have a certain...   \n",
       "1      [\"What is the difference between marriage lice...   \n",
       "2      [\"explain function calling. how would you call...   \n",
       "3      [\"How can I create a test set for a very rare ...   \n",
       "4      [\"What is the best way to travel from Tel-Aviv...   \n",
       "...                                                  ...   \n",
       "57472  [\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...   \n",
       "57473  [\"In python, implement a naive Bayes with gaus...   \n",
       "57474  [\"is it unethical to work on building weapons?...   \n",
       "57475  [\"If a bait contains 0,0025% bromadiolon then ...   \n",
       "57476  [\"three kids eat three apples in three days, h...   \n",
       "\n",
       "                                              response_a  \\\n",
       "0      [\"The question of whether it is morally right ...   \n",
       "1      [\"A marriage license is a legal document that ...   \n",
       "2      [\"Function calling is the process of invoking ...   \n",
       "3      [\"Creating a test set for a very rare category...   \n",
       "4      [\"The best way to travel from Tel Aviv to Jeru...   \n",
       "...                                                  ...   \n",
       "57472  [\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...   \n",
       "57473  [\"Here is an implementation of a naive Bayes c...   \n",
       "57474  [\"Working on weapons technology raises some et...   \n",
       "57475  [\"Bromadiolone is a rodenticide which is most ...   \n",
       "57476                                      [\"27 apples\"]   \n",
       "\n",
       "                                              response_b  winner_model_a  \\\n",
       "0      [\"As an AI, I don't have personal beliefs or o...               1   \n",
       "1      [\"A marriage license and a marriage certificat...               0   \n",
       "2      [\"Function calling is the process of invoking ...               0   \n",
       "3      [\"When building a classifier for a very rare c...               1   \n",
       "4      [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
       "...                                                  ...             ...   \n",
       "57472  [\"Here is how that mnemonic represents the dig...               1   \n",
       "57473  [\"Sure! Here's an implementation of a naive Ba...               1   \n",
       "57474  [\"It depends on the context. Weapons can be us...               1   \n",
       "57475  [\"As an AI language model, I do not promote or...               0   \n",
       "57476  [\"If three kids eat three apples in three days...               1   \n",
       "\n",
       "       winner_model_b  winner_tie  \n",
       "0                   0           0  \n",
       "1                   1           0  \n",
       "2                   0           1  \n",
       "3                   0           0  \n",
       "4                   1           0  \n",
       "...               ...         ...  \n",
       "57472               0           0  \n",
       "57473               0           0  \n",
       "57474               0           0  \n",
       "57475               1           0  \n",
       "57476               0           0  \n",
       "\n",
       "[57477 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec09a432",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T11:17:36.139039Z",
     "iopub.status.busy": "2024-06-18T11:17:36.138048Z",
     "iopub.status.idle": "2024-06-18T11:17:36.151513Z",
     "shell.execute_reply": "2024-06-18T11:17:36.150313Z"
    },
    "papermill": {
     "duration": 0.022356,
     "end_time": "2024-06-18T11:17:36.153796",
     "exception": false,
     "start_time": "2024-06-18T11:17:36.131440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        id                                             prompt  \\\n",
       " 0   136060  [\"I have three oranges today, I ate an orange ...   \n",
       " 1   211333  [\"You are a mediator in a heated political deb...   \n",
       " 2  1233961  [\"How to initialize the classification head wh...   \n",
       " \n",
       "                                           response_a  \\\n",
       " 0                    [\"You have two oranges today.\"]   \n",
       " 1  [\"Thank you for sharing the details of the sit...   \n",
       " 2  [\"When you want to initialize the classificati...   \n",
       " \n",
       "                                           response_b  \n",
       " 0  [\"You still have three oranges. Eating an oran...  \n",
       " 1  [\"Mr Reddy and Ms Blue both have valid points ...  \n",
       " 2  [\"To initialize the classification head when p...  ,\n",
       "         id  winner_model_a  winner_model_b  winner_tie\n",
       " 0   136060        0.333333        0.333333    0.333333\n",
       " 1   211333        0.333333        0.333333    0.333333\n",
       " 2  1233961        0.333333        0.333333    0.333333)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df, sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa0f370b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T11:17:36.166827Z",
     "iopub.status.busy": "2024-06-18T11:17:36.165673Z",
     "iopub.status.idle": "2024-06-18T11:17:36.216245Z",
     "shell.execute_reply": "2024-06-18T11:17:36.215084Z"
    },
    "papermill": {
     "duration": 0.059361,
     "end_time": "2024-06-18T11:17:36.218482",
     "exception": false,
     "start_time": "2024-06-18T11:17:36.159121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries in Trainset : 57477\n",
      "Unique models used as 'model_a': 64 | Unique models used as 'model_b': 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>count_a</th>\n",
       "      <th>count_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>3678</td>\n",
       "      <td>3709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>3553</td>\n",
       "      <td>3530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>3099</td>\n",
       "      <td>3066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>2859</td>\n",
       "      <td>2724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>2087</td>\n",
       "      <td>2035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>falcon-180b-chat</td>\n",
       "      <td>145</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>openchat-3.5-0106</td>\n",
       "      <td>108</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>qwen1.5-7b-chat</td>\n",
       "      <td>106</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>qwen1.5-4b-chat</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>mistral-7b-instruct-v0.2</td>\n",
       "      <td>54</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  count_a  count_b\n",
       "0         gpt-4-1106-preview     3678     3709\n",
       "1         gpt-3.5-turbo-0613     3553     3530\n",
       "2                 gpt-4-0613     3099     3066\n",
       "3                 claude-2.1     2859     2724\n",
       "4                 gpt-4-0314     2087     2035\n",
       "..                       ...      ...      ...\n",
       "59          falcon-180b-chat      145      141\n",
       "60         openchat-3.5-0106      108      136\n",
       "61           qwen1.5-7b-chat      106      102\n",
       "62           qwen1.5-4b-chat      100      100\n",
       "63  mistral-7b-instruct-v0.2       54       46\n",
       "\n",
       "[64 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Total entries in Trainset : {train_df.shape[0]}\")\n",
    "print(f\"Unique models used as 'model_a': {train_df['model_a'].nunique()} | Unique models used as 'model_b': {train_df['model_b'].nunique()}\")\n",
    "models_used = pd.DataFrame(train_df['model_a'].value_counts().reset_index().rename(columns={'model_a':'model', 'count': 'count_a'})).merge(pd.DataFrame(train_df['model_b'].value_counts().reset_index().rename(columns={'model_b':'model', 'count':'count_b'})), on=['model'])\n",
    "models_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eff829d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T11:17:36.230994Z",
     "iopub.status.busy": "2024-06-18T11:17:36.230595Z",
     "iopub.status.idle": "2024-06-18T11:17:36.247760Z",
     "shell.execute_reply": "2024-06-18T11:17:36.246783Z"
    },
    "papermill": {
     "duration": 0.026199,
     "end_time": "2024-06-18T11:17:36.250065",
     "exception": false,
     "start_time": "2024-06-18T11:17:36.223866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique base model : 39 : \n",
      "\t ['gpt', 'claude', 'vicuna', 'mixtral', 'mistral', 'llama', 'zephyr', 'palm', 'openchat', 'wizardlm', 'koala', 'oasst', 'codellama', 'gemini', 'pplx', 'alpaca', 'yi', 'chatglm', 'RWKV', 'tulu', 'starling', 'qwen', 'chatglm3', 'stripedhyena', 'fastchat', 'openhermes', 'mpt', 'solar', 'deepseek', 'dolly', 'stablelm', 'guanaco', 'llama2', 'chatglm2', 'qwen1.5', 'gpt4all', 'dolphin', 'nous', 'falcon']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>count_a</th>\n",
       "      <th>count_b</th>\n",
       "      <th>base_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>3678</td>\n",
       "      <td>3709</td>\n",
       "      <td>gpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>3553</td>\n",
       "      <td>3530</td>\n",
       "      <td>gpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>3099</td>\n",
       "      <td>3066</td>\n",
       "      <td>gpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>2859</td>\n",
       "      <td>2724</td>\n",
       "      <td>claude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>2087</td>\n",
       "      <td>2035</td>\n",
       "      <td>gpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>falcon-180b-chat</td>\n",
       "      <td>145</td>\n",
       "      <td>141</td>\n",
       "      <td>falcon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>openchat-3.5-0106</td>\n",
       "      <td>108</td>\n",
       "      <td>136</td>\n",
       "      <td>openchat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>qwen1.5-7b-chat</td>\n",
       "      <td>106</td>\n",
       "      <td>102</td>\n",
       "      <td>qwen1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>qwen1.5-4b-chat</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>qwen1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>mistral-7b-instruct-v0.2</td>\n",
       "      <td>54</td>\n",
       "      <td>46</td>\n",
       "      <td>mistral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  count_a  count_b base_model\n",
       "0         gpt-4-1106-preview     3678     3709        gpt\n",
       "1         gpt-3.5-turbo-0613     3553     3530        gpt\n",
       "2                 gpt-4-0613     3099     3066        gpt\n",
       "3                 claude-2.1     2859     2724     claude\n",
       "4                 gpt-4-0314     2087     2035        gpt\n",
       "..                       ...      ...      ...        ...\n",
       "59          falcon-180b-chat      145      141     falcon\n",
       "60         openchat-3.5-0106      108      136   openchat\n",
       "61           qwen1.5-7b-chat      106      102    qwen1.5\n",
       "62           qwen1.5-4b-chat      100      100    qwen1.5\n",
       "63  mistral-7b-instruct-v0.2       54       46    mistral\n",
       "\n",
       "[64 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = lambda x: x[\"model\"].split(\"-\")[0]\n",
    "models_used[\"base_model\"] = models_used.apply(f, axis=1)\n",
    "\n",
    "print(f\"Total unique base model : {models_used['base_model'].nunique()} : \\n\\t {list(models_used['base_model'].unique())}\")\n",
    "models_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81a91f81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T11:17:36.263158Z",
     "iopub.status.busy": "2024-06-18T11:17:36.262757Z",
     "iopub.status.idle": "2024-06-18T11:17:36.297672Z",
     "shell.execute_reply": "2024-06-18T11:17:36.296548Z"
    },
    "papermill": {
     "duration": 0.044473,
     "end_time": "2024-06-18T11:17:36.300182",
     "exception": false,
     "start_time": "2024-06-18T11:17:36.255709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model A : 20064, Model B : 19652, Tie : 17761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                  winner_model_a  winner_model_b  winner_tie\n",
       " model_a                                                     \n",
       " RWKV-4-Raven-14B             146             269         173\n",
       " alpaca-13b                   180             307         222\n",
       " chatglm-6b                   106             304         202\n",
       " chatglm2-6b                   35             161          87\n",
       " chatglm3-6b                   84             270         149\n",
       " ...                          ...             ...         ...\n",
       " wizardlm-13b                 275             242         281\n",
       " wizardlm-70b                 272             267         261\n",
       " yi-34b-chat                  237             228         231\n",
       " zephyr-7b-alpha               55              72          83\n",
       " zephyr-7b-beta               352             461         394\n",
       " \n",
       " [64 rows x 3 columns],\n",
       "                   winner_model_a  winner_model_b  winner_tie\n",
       " model_b                                                     \n",
       " RWKV-4-Raven-14B             265             119         186\n",
       " alpaca-13b                   319             176         199\n",
       " chatglm-6b                   305             111         233\n",
       " chatglm2-6b                  159              38          84\n",
       " chatglm3-6b                  268              73         145\n",
       " ...                          ...             ...         ...\n",
       " wizardlm-13b                 241             297         244\n",
       " wizardlm-70b                 267             316         261\n",
       " yi-34b-chat                  214             294         243\n",
       " zephyr-7b-alpha               76              64          62\n",
       " zephyr-7b-beta               449             362         383\n",
       " \n",
       " [64 rows x 3 columns])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Models wins comparisions\n",
    "# Simple model_a wins Vs model_b wins\n",
    "print(f\"Model A : {train_df['winner_model_a'].sum()}, Model B : {train_df['winner_model_b'].sum()}, Tie : {train_df['winner_tie'].sum()}\")\n",
    "\n",
    "# Models wins\n",
    "model_a_grp = train_df[[\"model_a\", \"winner_model_a\", \"winner_model_b\", \"winner_tie\"]].groupby([\"model_a\"]).sum()\n",
    "model_b_grp = train_df[[\"model_b\", \"winner_model_a\", \"winner_model_b\", \"winner_tie\"]].groupby([\"model_b\"]).sum()\n",
    "\n",
    "model_a_grp, model_b_grp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eddc03d",
   "metadata": {
    "papermill": {
     "duration": 0.00556,
     "end_time": "2024-06-18T11:17:36.311672",
     "exception": false,
     "start_time": "2024-06-18T11:17:36.306112",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data preperation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44a46b56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T11:17:36.326107Z",
     "iopub.status.busy": "2024-06-18T11:17:36.325698Z",
     "iopub.status.idle": "2024-06-18T11:17:36.330527Z",
     "shell.execute_reply": "2024-06-18T11:17:36.329372Z"
    },
    "papermill": {
     "duration": 0.015212,
     "end_time": "2024-06-18T11:17:36.332722",
     "exception": false,
     "start_time": "2024-06-18T11:17:36.317510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_df.drop(columns=[\"target\"], inplace=True)\n",
    "# train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2b670d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T11:17:36.347437Z",
     "iopub.status.busy": "2024-06-18T11:17:36.346947Z",
     "iopub.status.idle": "2024-06-18T11:17:36.568022Z",
     "shell.execute_reply": "2024-06-18T11:17:36.566690Z"
    },
    "papermill": {
     "duration": 0.23145,
     "end_time": "2024-06-18T11:17:36.570470",
     "exception": false,
     "start_time": "2024-06-18T11:17:36.339020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57477, 9)\n",
      "[\"Is it morally right to try to have a certain percentage of females on managerial positions?\",\"OK, does pineapple belong on a pizza? Relax and give me fun answer.\"]\n",
      "++++++++++++++++\n",
      "[\"The question of whether it is morally right to aim for a certain percentage of females in managerial positions is a complex ethical issue that involves considerations of fairness, equality, diversity, and discrimination.\\n\\nHere are some arguments in favor of and against such policies:\\n\\n**Arguments in favor:**\\n\\n1. **Correcting Historical Inequities:** Women have historically been underrepresented in leadership roles due to various cultural, institutional, and social barriers. Aiming for a specific percentage can be seen as a corrective measure to address past and ongoing discrimination.\\n\\n2. **Promoting Diversity:** Diverse leadership teams can enhance decision-making and represent a broader range of perspectives. This can lead to better outcomes for organizations and society as a whole.\\n\\n3. **Equality of Opportunity:** Setting targets for female representation in management can help ensure that women have equal opportunities to advance in their careers.\\n\\n4. **Role Modeling:** Increased visibility of female leaders can inspire and encourage other women and girls to pursue leadership roles.\\n\\n**Arguments against:**\\n\\n1. **Reverse Discrimination:** Setting a quota for female representation might lead to the perception or reality of reverse discrimination, where men might be overlooked for positions despite being qualified, simply to meet the gender target.\\n\\n2. **Meritocracy Concerns:** Critics argue that employment and promotion should be based solely on merit and qualifications, not gender. They fear that quotas could compromise the quality of leadership if less qualified individuals are promoted to meet gender targets.\\n\\n3. **Tokenism:** There is a risk that women appointed to meet quotas might be seen as \\\"tokens,\\\" undermining their legitimacy and potentially leading to resentment among colleagues.\\n\\n4. **Oversimplification of Diversity:** Focusing only on gender might overlook other important aspects of diversity, such as race, ethnicity, socioeconomic background, or sexual orientation.\\n\\nUltimately, the morality of aiming for a certain percentage of females in managerial positions depends on one's ethical framework and the context in which such policies are implemented. Proponents of gender diversity targets often argue that these measures are necessary as a transitional mechanism to create a level playing field, while opponents may argue for a \\\"color-blind\\\" or \\\"gender-blind\\\" approach to hiring and promotions.\\n\\nOrganizations and societies must carefully consider the implications of these strategies and strive to implement policies that promote fairness and equality while minimizing negative consequences. It is also important to address the root causes of gender inequality, such as unconscious bias, work-life balance challenges, and lack of supportive policies, to create an environment where everyone has the opportunity to succeed based on their capabilities and contributions.\",\"Ah, the age-old culinary conundrum that has divided nations and dinner tables: does pineapple belong on a pizza? The tropical twist of pineapple on pizza, known as Hawaiian pizza, is a hotly debated topic where taste buds battle and pizza purists protest.\\n\\nLet's slice into the debate with a zest of fun:\\n\\n**Team Pineapple:** \\\"Absolutely, yes! Pineapple on pizza is like a beach party in your mouth. The sweet juiciness of pineapple chunks frolicking with savory ham or bacon creates a flavor wave that surfs across the cheesy ocean of deliciousness. It's the Mardi Gras of pizzas, where sweet meets savory in a jubilant jamboree!\\\"\\n\\n**Team No-Pineapple:** \\\"No way, not in a million pizzas! Pineapple is a fruit that should be sunbathing on a tropical fruit platter, not freeloading on a sacred slice of pizza. The thought of warm, melty cheese conspiring with pineapple's sugary mischief is enough to make Italian ancestors turn in their tomato patches. Keep the pineapple in the fruit salad where it belongs!\\\"\\n\\nAt the end of the day, whether pineapple belongs on pizza is a matter of personal taste. Some say it's a match made in heaven, others say it's a culinary crime. But let's face it, in the world of pizza toppings, where you can find everything from anchovies to zucchini, there's room for a little pineapple pizzazz. So, if your taste buds crave that sweet and tangy twist, go ahead and let your pineapple flag fly atop that glorious cheese-covered dough. Bon app\\u00e9tit, or as they say in pineapple paradise, \\\"Aloha-ppetite!\\\" \\ud83c\\udf4d\\ud83c\\udf55\"]\n",
      "[\"Is it morally right to try to have a certain percentage of females on managerial positions?\",\"OK, does pineapple belong on a pizza? Relax and give me fun answer.\"][\"The question of whether it is morally right to aim for a certain percentage of females in managerial positions is a complex ethical issue that involves considerations of fairness, equality, diversity, and discrimination.\\n\\nHere are some arguments in favor of and against such policies:\\n\\n**Arguments in favor:**\\n\\n1. **Correcting Historical Inequities:** Women have historically been underrepresented in leadership roles due to various cultural, institutional, and social barriers. Aiming for a specific percentage can be seen as a corrective measure to address past and ongoing discrimination.\\n\\n2. **Promoting Diversity:** Diverse leadership teams can enhance decision-making and represent a broader range of perspectives. This can lead to better outcomes for organizations and society as a whole.\\n\\n3. **Equality of Opportunity:** Setting targets for female representation in management can help ensure that women have equal opportunities to advance in their careers.\\n\\n4. **Role Modeling:** Increased visibility of female leaders can inspire and encourage other women and girls to pursue leadership roles.\\n\\n**Arguments against:**\\n\\n1. **Reverse Discrimination:** Setting a quota for female representation might lead to the perception or reality of reverse discrimination, where men might be overlooked for positions despite being qualified, simply to meet the gender target.\\n\\n2. **Meritocracy Concerns:** Critics argue that employment and promotion should be based solely on merit and qualifications, not gender. They fear that quotas could compromise the quality of leadership if less qualified individuals are promoted to meet gender targets.\\n\\n3. **Tokenism:** There is a risk that women appointed to meet quotas might be seen as \\\"tokens,\\\" undermining their legitimacy and potentially leading to resentment among colleagues.\\n\\n4. **Oversimplification of Diversity:** Focusing only on gender might overlook other important aspects of diversity, such as race, ethnicity, socioeconomic background, or sexual orientation.\\n\\nUltimately, the morality of aiming for a certain percentage of females in managerial positions depends on one's ethical framework and the context in which such policies are implemented. Proponents of gender diversity targets often argue that these measures are necessary as a transitional mechanism to create a level playing field, while opponents may argue for a \\\"color-blind\\\" or \\\"gender-blind\\\" approach to hiring and promotions.\\n\\nOrganizations and societies must carefully consider the implications of these strategies and strive to implement policies that promote fairness and equality while minimizing negative consequences. It is also important to address the root causes of gender inequality, such as unconscious bias, work-life balance challenges, and lack of supportive policies, to create an environment where everyone has the opportunity to succeed based on their capabilities and contributions.\",\"Ah, the age-old culinary conundrum that has divided nations and dinner tables: does pineapple belong on a pizza? The tropical twist of pineapple on pizza, known as Hawaiian pizza, is a hotly debated topic where taste buds battle and pizza purists protest.\\n\\nLet's slice into the debate with a zest of fun:\\n\\n**Team Pineapple:** \\\"Absolutely, yes! Pineapple on pizza is like a beach party in your mouth. The sweet juiciness of pineapple chunks frolicking with savory ham or bacon creates a flavor wave that surfs across the cheesy ocean of deliciousness. It's the Mardi Gras of pizzas, where sweet meets savory in a jubilant jamboree!\\\"\\n\\n**Team No-Pineapple:** \\\"No way, not in a million pizzas! Pineapple is a fruit that should be sunbathing on a tropical fruit platter, not freeloading on a sacred slice of pizza. The thought of warm, melty cheese conspiring with pineapple's sugary mischief is enough to make Italian ancestors turn in their tomato patches. Keep the pineapple in the fruit salad where it belongs!\\\"\\n\\nAt the end of the day, whether pineapple belongs on pizza is a matter of personal taste. Some say it's a match made in heaven, others say it's a culinary crime. But let's face it, in the world of pizza toppings, where you can find everything from anchovies to zucchini, there's room for a little pineapple pizzazz. So, if your taste buds crave that sweet and tangy twist, go ahead and let your pineapple flag fly atop that glorious cheese-covered dough. Bon app\\u00e9tit, or as they say in pineapple paradise, \\\"Aloha-ppetite!\\\" \\ud83c\\udf4d\\ud83c\\udf55\"]\n",
      "++++++++++++++++\n",
      "[\"As an AI, I don't have personal beliefs or opinions. However, I can tell you that the question of gender quotas in managerial positions is a complex one and positions can vary. Advocates argue that such measures can help correct historical imbalances, promote diversity, and may lead to better decision-making. Critics may argue that positions should be based purely on merit, and that quotas could potentially lead to tokenism or unqualified candidates being promoted. Morality can be subjective and differs from person to person based on their personal beliefs, cultural background, and values. It's a topic with valid arguments on both sides, and it's up to each individual or organization to decide what they believe is right.\",\"As an AI, I don't eat, so I don't have personal preferences. But, in the world of pizza, the pineapple topping is a hotly debated topic! Some people love the sweet and savory mix it brings to a pizza, a flavor combination made famous by the Hawaiian pizza. Others firmly believe that the sweetness of the fruit has no place on a pizza. It's a pizza puzzle that might never be solved. So, whether pineapple belongs on a pizza or not, it truly depends on your taste buds!\"]\n",
      "[\"Is it morally right to try to have a certain percentage of females on managerial positions?\",\"OK, does pineapple belong on a pizza? Relax and give me fun answer.\"][\"As an AI, I don't have personal beliefs or opinions. However, I can tell you that the question of gender quotas in managerial positions is a complex one and positions can vary. Advocates argue that such measures can help correct historical imbalances, promote diversity, and may lead to better decision-making. Critics may argue that positions should be based purely on merit, and that quotas could potentially lead to tokenism or unqualified candidates being promoted. Morality can be subjective and differs from person to person based on their personal beliefs, cultural background, and values. It's a topic with valid arguments on both sides, and it's up to each individual or organization to decide what they believe is right.\",\"As an AI, I don't eat, so I don't have personal preferences. But, in the world of pizza, the pineapple topping is a hotly debated topic! Some people love the sweet and savory mix it brings to a pizza, a flavor combination made famous by the Hawaiian pizza. Others firmly believe that the sweetness of the fruit has no place on a pizza. It's a pizza puzzle that might never be solved. So, whether pineapple belongs on a pizza or not, it truly depends on your taste buds!\"]\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "# print(train_df.head())\n",
    "\n",
    "train_df[\"target\"] = pd.factorize(train_df[[\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]].idxmax(axis=1))[0]\n",
    "train_df[\"prompt_reply_a\"] = train_df[\"prompt\"] + train_df[\"response_a\"]\n",
    "train_df[\"prompt_reply_b\"] = train_df[\"prompt\"] + train_df[\"response_b\"]\n",
    "print(train_df.iloc[0][\"prompt\"])\n",
    "print(\"++++++++++++++++\")\n",
    "print(train_df.iloc[0][\"response_a\"])\n",
    "print(train_df.iloc[0][\"prompt_reply_a\"])\n",
    "print(\"++++++++++++++++\")\n",
    "print(train_df.iloc[0][\"response_b\"])\n",
    "print(train_df.iloc[0][\"prompt_reply_b\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "923da0c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T11:17:36.584687Z",
     "iopub.status.busy": "2024-06-18T11:17:36.584291Z",
     "iopub.status.idle": "2024-06-18T11:17:36.919733Z",
     "shell.execute_reply": "2024-06-18T11:17:36.918601Z"
    },
    "papermill": {
     "duration": 0.34535,
     "end_time": "2024-06-18T11:17:36.922158",
     "exception": false,
     "start_time": "2024-06-18T11:17:36.576808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>target</th>\n",
       "      <th>prompt_reply_a</th>\n",
       "      <th>prompt_reply_b</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"A marriage license is a legal document that ...</td>\n",
       "      <td>[\"A marriage license and a marriage certificat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[\"How can I create a test set for a very rare ...</td>\n",
       "      <td>[\"Creating a test set for a very rare category...</td>\n",
       "      <td>[\"When building a classifier for a very rare c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"How can I create a test set for a very rare ...</td>\n",
       "      <td>[\"How can I create a test set for a very rare ...</td>\n",
       "      <td>[\"How can I create a test set for a very rare ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
       "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
       "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
       "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
       "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57472</th>\n",
       "      <td>4294656694</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>[\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...</td>\n",
       "      <td>[\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...</td>\n",
       "      <td>[\"Here is how that mnemonic represents the dig...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...</td>\n",
       "      <td>[\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...</td>\n",
       "      <td>[\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57473</th>\n",
       "      <td>4294692063</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>[\"In python, implement a naive Bayes with gaus...</td>\n",
       "      <td>[\"Here is an implementation of a naive Bayes c...</td>\n",
       "      <td>[\"Sure! Here's an implementation of a naive Ba...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"In python, implement a naive Bayes with gaus...</td>\n",
       "      <td>[\"In python, implement a naive Bayes with gaus...</td>\n",
       "      <td>[\"In python, implement a naive Bayes with gaus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57474</th>\n",
       "      <td>4294710549</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>[\"is it unethical to work on building weapons?...</td>\n",
       "      <td>[\"Working on weapons technology raises some et...</td>\n",
       "      <td>[\"It depends on the context. Weapons can be us...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"is it unethical to work on building weapons?...</td>\n",
       "      <td>[\"is it unethical to work on building weapons?...</td>\n",
       "      <td>[\"is it unethical to work on building weapons?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57475</th>\n",
       "      <td>4294899228</td>\n",
       "      <td>palm-2</td>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>[\"If a bait contains 0,0025% bromadiolon then ...</td>\n",
       "      <td>[\"Bromadiolone is a rodenticide which is most ...</td>\n",
       "      <td>[\"As an AI language model, I do not promote or...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"If a bait contains 0,0025% bromadiolon then ...</td>\n",
       "      <td>[\"If a bait contains 0,0025% bromadiolon then ...</td>\n",
       "      <td>[\"If a bait contains 0,0025% bromadiolon then ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57476</th>\n",
       "      <td>4294947231</td>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>[\"three kids eat three apples in three days, h...</td>\n",
       "      <td>[\"27 apples\"]</td>\n",
       "      <td>[\"If three kids eat three apples in three days...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"three kids eat three apples in three days, h...</td>\n",
       "      <td>[\"three kids eat three apples in three days, h...</td>\n",
       "      <td>[\"three kids eat three apples in three days, h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57477 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             model_a              model_b  \\\n",
       "0           30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1           53567           koala-13b           gpt-4-0613   \n",
       "2           65089  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3           96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4          198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "...           ...                 ...                  ...   \n",
       "57472  4294656694          gpt-4-0613             claude-1   \n",
       "57473  4294692063          claude-2.0     llama-2-13b-chat   \n",
       "57474  4294710549            claude-1           alpaca-13b   \n",
       "57475  4294899228              palm-2       tulu-2-dpo-70b   \n",
       "57476  4294947231  gemini-pro-dev-api   gpt-4-1106-preview   \n",
       "\n",
       "                                                  prompt  \\\n",
       "0      [\"Is it morally right to try to have a certain...   \n",
       "1      [\"What is the difference between marriage lice...   \n",
       "2      [\"explain function calling. how would you call...   \n",
       "3      [\"How can I create a test set for a very rare ...   \n",
       "4      [\"What is the best way to travel from Tel-Aviv...   \n",
       "...                                                  ...   \n",
       "57472  [\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...   \n",
       "57473  [\"In python, implement a naive Bayes with gaus...   \n",
       "57474  [\"is it unethical to work on building weapons?...   \n",
       "57475  [\"If a bait contains 0,0025% bromadiolon then ...   \n",
       "57476  [\"three kids eat three apples in three days, h...   \n",
       "\n",
       "                                              response_a  \\\n",
       "0      [\"The question of whether it is morally right ...   \n",
       "1      [\"A marriage license is a legal document that ...   \n",
       "2      [\"Function calling is the process of invoking ...   \n",
       "3      [\"Creating a test set for a very rare category...   \n",
       "4      [\"The best way to travel from Tel Aviv to Jeru...   \n",
       "...                                                  ...   \n",
       "57472  [\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...   \n",
       "57473  [\"Here is an implementation of a naive Bayes c...   \n",
       "57474  [\"Working on weapons technology raises some et...   \n",
       "57475  [\"Bromadiolone is a rodenticide which is most ...   \n",
       "57476                                      [\"27 apples\"]   \n",
       "\n",
       "                                              response_b  winner_model_a  \\\n",
       "0      [\"As an AI, I don't have personal beliefs or o...               1   \n",
       "1      [\"A marriage license and a marriage certificat...               0   \n",
       "2      [\"Function calling is the process of invoking ...               0   \n",
       "3      [\"When building a classifier for a very rare c...               1   \n",
       "4      [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
       "...                                                  ...             ...   \n",
       "57472  [\"Here is how that mnemonic represents the dig...               1   \n",
       "57473  [\"Sure! Here's an implementation of a naive Ba...               1   \n",
       "57474  [\"It depends on the context. Weapons can be us...               1   \n",
       "57475  [\"As an AI language model, I do not promote or...               0   \n",
       "57476  [\"If three kids eat three apples in three days...               1   \n",
       "\n",
       "       winner_model_b  winner_tie  target  \\\n",
       "0                   0           0       0   \n",
       "1                   1           0       1   \n",
       "2                   0           1       2   \n",
       "3                   0           0       0   \n",
       "4                   1           0       1   \n",
       "...               ...         ...     ...   \n",
       "57472               0           0       0   \n",
       "57473               0           0       0   \n",
       "57474               0           0       0   \n",
       "57475               1           0       1   \n",
       "57476               0           0       0   \n",
       "\n",
       "                                          prompt_reply_a  \\\n",
       "0      [\"Is it morally right to try to have a certain...   \n",
       "1      [\"What is the difference between marriage lice...   \n",
       "2      [\"explain function calling. how would you call...   \n",
       "3      [\"How can I create a test set for a very rare ...   \n",
       "4      [\"What is the best way to travel from Tel-Aviv...   \n",
       "...                                                  ...   \n",
       "57472  [\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...   \n",
       "57473  [\"In python, implement a naive Bayes with gaus...   \n",
       "57474  [\"is it unethical to work on building weapons?...   \n",
       "57475  [\"If a bait contains 0,0025% bromadiolon then ...   \n",
       "57476  [\"three kids eat three apples in three days, h...   \n",
       "\n",
       "                                          prompt_reply_b  \\\n",
       "0      [\"Is it morally right to try to have a certain...   \n",
       "1      [\"What is the difference between marriage lice...   \n",
       "2      [\"explain function calling. how would you call...   \n",
       "3      [\"How can I create a test set for a very rare ...   \n",
       "4      [\"What is the best way to travel from Tel-Aviv...   \n",
       "...                                                  ...   \n",
       "57472  [\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...   \n",
       "57473  [\"In python, implement a naive Bayes with gaus...   \n",
       "57474  [\"is it unethical to work on building weapons?...   \n",
       "57475  [\"If a bait contains 0,0025% bromadiolon then ...   \n",
       "57476  [\"three kids eat three apples in three days, h...   \n",
       "\n",
       "                                                    text  \n",
       "0      [\"Is it morally right to try to have a certain...  \n",
       "1      [\"What is the difference between marriage lice...  \n",
       "2      [\"explain function calling. how would you call...  \n",
       "3      [\"How can I create a test set for a very rare ...  \n",
       "4      [\"What is the best way to travel from Tel-Aviv...  \n",
       "...                                                  ...  \n",
       "57472  [\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...  \n",
       "57473  [\"In python, implement a naive Bayes with gaus...  \n",
       "57474  [\"is it unethical to work on building weapons?...  \n",
       "57475  [\"If a bait contains 0,0025% bromadiolon then ...  \n",
       "57476  [\"three kids eat three apples in three days, h...  \n",
       "\n",
       "[57477 rows x 13 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"text\"] = train_df[\"prompt\"] + train_df[\"response_a\"] + train_df[\"response_b\"]\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14fea2d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T11:17:36.937808Z",
     "iopub.status.busy": "2024-06-18T11:17:36.937437Z",
     "iopub.status.idle": "2024-06-18T11:17:38.335677Z",
     "shell.execute_reply": "2024-06-18T11:17:38.334412Z"
    },
    "papermill": {
     "duration": 1.409122,
     "end_time": "2024-06-18T11:17:38.338137",
     "exception": false,
     "start_time": "2024-06-18T11:17:36.929015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45981, 2) (11496, 2) (45981,) (11496,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = train_df[[\"text\",\"prompt_reply_a\", \"prompt_reply_b\", \"target\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[[\"prompt_reply_a\", \"prompt_reply_b\"]], df[\"target\"], test_size=0.2, random_state=100)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ff8007",
   "metadata": {
    "papermill": {
     "duration": 0.006568,
     "end_time": "2024-06-18T11:17:38.352822",
     "exception": false,
     "start_time": "2024-06-18T11:17:38.346254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tf-Idf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03fb2c9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T11:17:38.368013Z",
     "iopub.status.busy": "2024-06-18T11:17:38.367600Z",
     "iopub.status.idle": "2024-06-18T11:18:43.320825Z",
     "shell.execute_reply": "2024-06-18T11:18:43.319739Z"
    },
    "papermill": {
     "duration": 64.972169,
     "end_time": "2024-06-18T11:18:43.331776",
     "exception": false,
     "start_time": "2024-06-18T11:17:38.359607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00000</th>\n",
       "      <th>000000</th>\n",
       "      <th>00000000</th>\n",
       "      <th>000000000</th>\n",
       "      <th>0000000000000000</th>\n",
       "      <th>00000000000000000</th>\n",
       "      <th>00000000000000000000000</th>\n",
       "      <th>...</th>\n",
       "      <th>zyxel</th>\n",
       "      <th>zyxor</th>\n",
       "      <th>zyxwvutsrqponmlkjihgfedcba</th>\n",
       "      <th>zz</th>\n",
       "      <th>zzgl</th>\n",
       "      <th>zzxf</th>\n",
       "      <th>zzz</th>\n",
       "      <th>zzzz</th>\n",
       "      <th>zzzzz</th>\n",
       "      <th>zzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57472</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57473</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57474</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57475</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57476</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57477 rows × 287185 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        00  000  0000  00000  000000  00000000  000000000  0000000000000000  \\\n",
       "0      0.0  0.0   0.0    0.0     0.0       0.0        0.0               0.0   \n",
       "1      0.0  0.0   0.0    0.0     0.0       0.0        0.0               0.0   \n",
       "2      0.0  0.0   0.0    0.0     0.0       0.0        0.0               0.0   \n",
       "3      0.0  0.0   0.0    0.0     0.0       0.0        0.0               0.0   \n",
       "4      0.0  0.0   0.0    0.0     0.0       0.0        0.0               0.0   \n",
       "...    ...  ...   ...    ...     ...       ...        ...               ...   \n",
       "57472  0.0  0.0   0.0    0.0     0.0       0.0        0.0               0.0   \n",
       "57473  0.0  0.0   0.0    0.0     0.0       0.0        0.0               0.0   \n",
       "57474  0.0  0.0   0.0    0.0     0.0       0.0        0.0               0.0   \n",
       "57475  0.0  0.0   0.0    0.0     0.0       0.0        0.0               0.0   \n",
       "57476  0.0  0.0   0.0    0.0     0.0       0.0        0.0               0.0   \n",
       "\n",
       "       00000000000000000  00000000000000000000000  ...  zyxel  zyxor  \\\n",
       "0                    0.0                      0.0  ...    0.0    0.0   \n",
       "1                    0.0                      0.0  ...    0.0    0.0   \n",
       "2                    0.0                      0.0  ...    0.0    0.0   \n",
       "3                    0.0                      0.0  ...    0.0    0.0   \n",
       "4                    0.0                      0.0  ...    0.0    0.0   \n",
       "...                  ...                      ...  ...    ...    ...   \n",
       "57472                0.0                      0.0  ...    0.0    0.0   \n",
       "57473                0.0                      0.0  ...    0.0    0.0   \n",
       "57474                0.0                      0.0  ...    0.0    0.0   \n",
       "57475                0.0                      0.0  ...    0.0    0.0   \n",
       "57476                0.0                      0.0  ...    0.0    0.0   \n",
       "\n",
       "       zyxwvutsrqponmlkjihgfedcba   zz  zzgl  zzxf  zzz  zzzz  zzzzz  zzzzzz  \n",
       "0                             0.0  0.0   0.0   0.0  0.0   0.0    0.0     0.0  \n",
       "1                             0.0  0.0   0.0   0.0  0.0   0.0    0.0     0.0  \n",
       "2                             0.0  0.0   0.0   0.0  0.0   0.0    0.0     0.0  \n",
       "3                             0.0  0.0   0.0   0.0  0.0   0.0    0.0     0.0  \n",
       "4                             0.0  0.0   0.0   0.0  0.0   0.0    0.0     0.0  \n",
       "...                           ...  ...   ...   ...  ...   ...    ...     ...  \n",
       "57472                         0.0  0.0   0.0   0.0  0.0   0.0    0.0     0.0  \n",
       "57473                         0.0  0.0   0.0   0.0  0.0   0.0    0.0     0.0  \n",
       "57474                         0.0  0.0   0.0   0.0  0.0   0.0    0.0     0.0  \n",
       "57475                         0.0  0.0   0.0   0.0  0.0   0.0    0.0     0.0  \n",
       "57476                         0.0  0.0   0.0   0.0  0.0   0.0    0.0     0.0  \n",
       "\n",
       "[57477 rows x 287185 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tf-Idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vec = TfidfVectorizer()\n",
    "tf_vec = vec.fit_transform(df[\"text\"])\n",
    "\n",
    "df_vec = pd.DataFrame(tf_vec.toarray(), columns=vec.get_feature_names_out())\n",
    "df_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "292cec8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T11:18:43.348803Z",
     "iopub.status.busy": "2024-06-18T11:18:43.348435Z",
     "iopub.status.idle": "2024-06-18T11:18:43.359543Z",
     "shell.execute_reply": "2024-06-18T11:18:43.358287Z"
    },
    "papermill": {
     "duration": 0.022013,
     "end_time": "2024-06-18T11:18:43.361781",
     "exception": false,
     "start_time": "2024-06-18T11:18:43.339768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tf-Idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_transformed = vectorizer.fit_transform(X_train)\n",
    "X_test_transformed = vectorizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a70ebf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T11:18:43.378380Z",
     "iopub.status.busy": "2024-06-18T11:18:43.377961Z",
     "iopub.status.idle": "2024-06-18T11:18:43.389511Z",
     "shell.execute_reply": "2024-06-18T11:18:43.388231Z"
    },
    "papermill": {
     "duration": 0.022477,
     "end_time": "2024-06-18T11:18:43.391625",
     "exception": false,
     "start_time": "2024-06-18T11:18:43.369148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_reply_a</th>\n",
       "      <th>prompt_reply_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prompt_reply_a  prompt_reply_b\n",
       "0             1.0             0.0\n",
       "1             0.0             1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed.toarray(), vectorizer.get_feature_names_out()\n",
    "train_transformed_df = pd.DataFrame(X_train_transformed.toarray(), columns= vectorizer.get_feature_names_out())\n",
    "train_transformed_df"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 77.758215,
   "end_time": "2024-06-18T11:18:46.019891",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-18T11:17:28.261676",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
